{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "from collections import deque\n",
    "from tensorflow.keras import Model, Sequential \n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (BatchNormalization, Flatten, Dense, ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_savefolder = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    print('-------------------')\n",
    "    if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "        print(\"GPU available.\")\n",
    "        device = '/gpu:0'\n",
    "    else:\n",
    "        print(\"No GPU available.\")\n",
    "        device = '/cpu:0'\n",
    "    print('-------------------')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, action_space, batch_size=3, replay_memory_size=5, epsilon=0.1, \n",
    "                 learning_rate=1e-3, discount_factor=1., load=False, save=True):\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_memory_size = replay_memory_size\n",
    "    \n",
    "        self.replay_memory = deque(maxlen=replay_memory_size)\n",
    "        \n",
    "        self.action_space = action_space\n",
    "        self.criterion = MeanSquaredError()\n",
    "        \n",
    "        self.device = set_device()\n",
    "        \n",
    "        self.save = save\n",
    "        #self.opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "        self.opt = Adam(lr=self.lr)\n",
    "        \n",
    "        if load:\n",
    "            print('--------------------')\n",
    "            print(f'Loading model from: {0}')\n",
    "            print('--------------------')\n",
    "            self.dqn = tf.keras.models.load_model(model_savefolder)\n",
    "            self.dqn.build((None, 4))\n",
    "        else:\n",
    "            self.dqn = DQN(self.action_space)\n",
    "            self.dqn.build((None, 4))\n",
    "        \n",
    "    def choose_action(self, obs):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            return np.random.choice(self.action_space)\n",
    "        else:\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            \n",
    "            action = np.argmax(self.dqn(obs), axis=1)[0]\n",
    "            \n",
    "            return action\n",
    "    \n",
    "    def remember(self, obs, action, reward, next_obs, done):\n",
    "        self.replay_memory.append([obs, action, reward, next_obs, done])\n",
    "        \n",
    "    def train(self):\n",
    "        batch = random.sample(self.replay_memory, self.batch_size)\n",
    "        batch = np.array(batch, dtype=object)\n",
    "     \n",
    "        obs = tf.stack(batch[:, 0])\n",
    "        actions = batch[:, 1]\n",
    "        rewards = tf.stack(batch[:, 2])\n",
    "        next_obs = tf.stack(batch[:, 3])  \n",
    "        dones = tf.stack(batch[:, 4])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.dqn.trainable_variables)\n",
    "        \n",
    "            q_obs = self.dqn(obs)\n",
    "            q_next_obs = self.dqn(next_obs)\n",
    "\n",
    "            targets = tf.where(dones, rewards, self.discount_factor * tf.math.reduce_max(q_next_obs, axis=1))\n",
    "           \n",
    "            action_idx = tf.stack([list(range(len(actions))), actions], axis=1)\n",
    "            q_obs = tf.gather_nd(q_obs, action_idx) # corresponding to taken actions\n",
    "            \n",
    "            loss = self.criterion(targets, q_obs) # td error\n",
    "            \n",
    "            print(loss)\n",
    "        grads = tape.gradient(loss, self.dqn.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.dqn.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Model):\n",
    "    \"\"\" Deep Q-learning network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_actions, num_obs=4):\n",
    "        super(DQN, self).__init__()\n",
    "        self.device = set_device()\n",
    "        \n",
    "        self.layer = Sequential([Dense(24),\n",
    "                                 ReLU(),\n",
    "                                 Dense(num_actions),\n",
    "                                 ReLU()])\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(env, agent, T=10):\n",
    "    step = 0\n",
    "    \n",
    "    for i in range(T):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "            action = agent.choose_action(obs)\n",
    "            \n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            agent.remember(obs, action, reward, next_obs, done)\n",
    "            \n",
    "            if step > agent.replay_memory_size:\n",
    "                agent.train()\n",
    "            \n",
    "            if agent.save:\n",
    "                agent.dqn.save(model_savefolder)\n",
    "            \n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    \n",
    "    \"\"\"\n",
    "        observation: {cart position (0), cart velocity (1), pole angle (2), pole angle velocity (3)}\n",
    "        \n",
    "        action: {push cart to the left (0) or right (1)}\n",
    "    \"\"\"\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    \n",
    "    agent = DQNAgent(action_space=action_space, save=False)\n",
    "    \n",
    "    run_training(env, agent)\n",
    "    \n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    #while True:\n",
    "    #    env.render()\n",
    "    #    action = agent.choose_action(obs)\n",
    "\n",
    "    #    next_obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "No GPU available.\n",
      "-------------------\n",
      "-------------------\n",
      "No GPU available.\n",
      "-------------------\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3333358, shape=(), dtype=float32)\n",
      "tf.Tensor(7.8208967e-07, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0024707902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0022942487, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023923941, shape=(), dtype=float32)\n",
      "tf.Tensor(0.045234, shape=(), dtype=float32)\n",
      "tf.Tensor(0.055033445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08071706, shape=(), dtype=float32)\n",
      "tf.Tensor(0.081545025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10593635, shape=(), dtype=float32)\n",
      "tf.Tensor(0.110720575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.112123765, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06555561, shape=(), dtype=float32)\n",
      "tf.Tensor(0.067108445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36641982, shape=(), dtype=float32)\n",
      "tf.Tensor(0.015611, shape=(), dtype=float32)\n",
      "tf.Tensor(0.015519497, shape=(), dtype=float32)\n",
      "tf.Tensor(0.036829468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018812615, shape=(), dtype=float32)\n",
      "tf.Tensor(0.041972607, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34644416, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027729318, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014982335, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3286805, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32769153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33333334, shape=(), dtype=float32)\n",
      "tf.Tensor(1.20784725e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3333602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33336267, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3143242e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3008524e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(7.607916e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(8.17689e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9173094e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(5.262667e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32817534, shape=(), dtype=float32)\n",
      "tf.Tensor(7.922071e-05, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32740453, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3264314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009684213, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010058607, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001023254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010228305, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010067816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31356648, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3127475, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001246647, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3104071, shape=(), dtype=float32)\n",
      "tf.Tensor(0.308979, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0017544768, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0019072505, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020376074, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0021489405, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3040067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015915519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30157432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00090230006, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29933664, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015840092, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016830122, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002642696, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027464435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0028305578, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0028957354, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002942877, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0029730245, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2998831, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027450414, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29876938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002145645, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020839435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0021052854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020807756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0024844932, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3023449, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
